resources:
  jobs:
    kedro_project_irisunity:
      name: kedro_project_irisunity
      max_concurrent_runs: 1
      job_clusters:
      - job_cluster_key: default
        new_cluster:
          node_type_id: Standard_D4ds_v4
          num_workers: 1
          spark_env_vars:
            KEDRO_LOGGING_CONFIG: /dbfs/FileStore/kedro_project/conf/logging.yml
          spark_version: 14.3.x-scala2.12
      tasks:
      - task_key: unity_split
        job_cluster_key: default
        python_wheel_task:
          entry_point: databricks_run
          package_name: kedro_project
          parameters:
          - --nodes
          - unity_split
          - --conf-source
          - /dbfs/FileStore/kedro_project/conf
          - --package-name
          - kedro_project
        libraries:
        - whl: ../dist/*.whl
      - task_key: unity_make_predictions
        job_cluster_key: default
        depends_on:
        - task_key: unity_split
        python_wheel_task:
          entry_point: databricks_run
          package_name: kedro_project
          parameters:
          - --nodes
          - unity_make_predictions
          - --conf-source
          - /dbfs/FileStore/kedro_project/conf
          - --package-name
          - kedro_project
        libraries:
        - whl: ../dist/*.whl
      - task_key: unity_report_accuracy
        job_cluster_key: default
        depends_on:
        - task_key: unity_split
        - task_key: unity_make_predictions
        python_wheel_task:
          entry_point: databricks_run
          package_name: kedro_project
          parameters:
          - --nodes
          - unity_report_accuracy
          - --conf-source
          - /dbfs/FileStore/kedro_project/conf
          - --package-name
          - kedro_project
        libraries:
        - whl: ../dist/*.whl
      format: MULTI_TASK
      queue:
        enabled: true
